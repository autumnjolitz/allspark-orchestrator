#!/bin/bash

function wait_for_cluster {
    while true; do
        ALIVE_WORKERS=`curl -s http://localhost:8080 | grep "Alive Workers" | html2text | awk '{ print $3 }'`
        if [ "$ALIVE_WORKERS" == "$EXPECTED_WORKERS" ]; then
            echo "cluster ready" >>/spark/status
            break
        fi
        echo "waiting for worker nodes" >>/spark/status
        sleep 1
    done
}

JAVA_HOME="/usr/lib/jvm/java-1.8-openjdk"
SPARK_HOME="/spark/spark-2.4.3-bin-hadoop2.7"

if [ -z $MASTER_URL ]; then
    $SPARK_HOME/sbin/start-master.sh
    wait_for_cluster
    /spark/run
else
    $SPARK_HOME/sbin/start-slave.sh $MASTER_URL
fi

while true; do

    pgrep -f hadoop
    if [ "$?" != "0" ]; then
        break
    fi
    sleep 10
done
