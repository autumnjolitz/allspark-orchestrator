#!/bin/bash

function wait_for_h2o_cluster {
    while true; do
        H2O_CLUSTER_SIZE=`curl -s http://localhost:54321/3/Cloud | jq .cloud_size`
        if [ "$H2O_CLUSTER_SIZE" == "$EXPECTED_WORKERS" ]; then
            echo "cluster ready" >>/spark/h2o_status
            break
        fi
        echo "waiting for h2o executors" >>/spark/h2o_status
        sleep 1
    done
}

function wait_for_spark_cluster {
    while true; do
        ALIVE_WORKERS=`curl -s http://localhost:8080 | grep "Alive Workers" | html2text | awk '{ print $3 }'`
        if [ "$ALIVE_WORKERS" == "$EXPECTED_WORKERS" ]; then
            echo "cluster ready" >>/spark/status
            break
        fi
        echo "waiting for worker nodes" >>/spark/status
        sleep 1
    done
}

JAVA_HOME="/usr/lib/jvm/java-1.8-openjdk"
SPARK_HOME="/spark/spark-2.4.3-bin-hadoop2.7"
MASTER="spark://$HOSTNAME:7077"

if [ -z $MASTER_URL ]; then
    $SPARK_HOME/sbin/start-master.sh
    wait_for_spark_cluster
    sparkling-water-2.4.13/bin/run-sparkling.sh &
    wait_for_h2o_cluster
    /spark/run
else
    $SPARK_HOME/sbin/start-slave.sh $MASTER_URL
fi

while true; do

    pgrep -f hadoop
    if [ "$?" != "0" ]; then
        break
    fi
    sleep 10
done
