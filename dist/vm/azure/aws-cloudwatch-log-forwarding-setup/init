#!/bin/bash -x

META_URL="http://169.254.169.254/metadata/instance?api-version=2019-06-01"

##
# AWS presigned URLs can be ~1.5Kb in length, which exceeds the 256 characters
# limit for Azure tags. To work around this, one can break the URL apart 
# into multiple tags (e.g. LOGGING_CREDENTIALS_URL_PART_1, 
# LOGGING_CREDENTIALS_URL_PART_2, etc.) # and then concatenate them to 
# obtain the download URL.
##
if [ -z $LOGGING_CREDENTIALS_URL ]; then
    source /allspark/env.sh
    LOGGING_CREDENTIALS_URL=""
    IDX=1
    while true; do
        CURRENT_PART="LOGGING_CREDENTIALS_URL_PART_$IDX"
        if [ -z ${!CURRENT_PART} ]; then
            break
        fi
        LOGGING_CREDENTIALS_URL+=${!CURRENT_PART}
        IDX=$(($IDX + 1))
    done
fi

function set_host_name {
        while true; do
                curl -s -H Metadata:true --noproxy "*" $META_URL | jq '.compute.name' | sed -e 's/"//g' >/etc/hostname
                if [ "$?" == "0" ]; then
                        break
                fi
                sleep 1
        done
        /bin/hostname -F /etc/hostname
        export HOSTNAME=`/bin/hostname`
}

function set_env_variables {
        /usr/bin/curl -s -H Metadata:true --noproxy "*" $META_URL | jq '.compute.tags' | sed -e 's/"//g' | python3 /allspark/write_env.py
        source /allspark/env.sh
}

function mount_shared_volume {
        if [ ! -z $MASTER_IP ]; then
                mount $MASTER_IP:/shared /shared
        fi
}

function run_allspark_image {
        DNS=`cat /etc/resolv.conf | grep nameserver | awk '{print $2}' | sed 1q`
        docker run --dns $DNS -d --log-driver syslog --ulimit nofile=122880:122880 --env-file /allspark/env.sh --network host --mount type=bind,source=/shared,target=/shared allspark-worker:latest
        tail -f /dev/null
}

function set_credentials {
    RAMDISK_PATH=/ramdisk
    CREDENTIAL_PATH=$RAMDISK_PATH/.aws

    mkdir $RAMDISK_PATH
    mount -t tmpfs -o rw,size=1M tmpfs $RAMDISK_PATH
    mkdir $CREDENTIAL_PATH
    curl -s --output $CREDENTIAL_PATH/credentials.zip "$LOGGING_CREDENTIALS_URL"
    unzip $CREDENTIAL_PATH/credentials.zip -d $CREDENTIAL_PATH
    rm $CREDENTIAL_PATH/credentials.zip
    ln -s $CREDENTIAL_PATH /root/.aws
}

function configure_logging {
    sed -i "s/_AZURE_SPARK_NODE_/$HOSTNAME/" /allspark/awslogs.conf
    curl https://s3.amazonaws.com/aws-cloudwatch/downloads/latest/awslogs-agent-setup.py -O
    python ./awslogs-agent-setup.py --region us-east-1 --non-interactive --configfile=/allspark/awslogs.conf
}

set_host_name
set_env_variables
set_credentials
configure_logging
mount_shared_volume
run_allspark_image
