#!/bin/bash -x

META_URL="http://169.254.169.254/metadata/instance?api-version=2019-06-01"

function set_host_name {
        while true; do
                curl -s -H Metadata:true --noproxy "*" $META_URL | jq '.compute.name' | sed -e 's/"//g' >/etc/hostname
                if [ "$?" == "0" ]; then
                        break
                fi
                sleep 1
        done
        /bin/hostname -F /etc/hostname
        export HOSTNAME=`/bin/hostname`
}

function set_env_variables {
        /usr/bin/curl -s -H Metadata:true --noproxy "*" $META_URL | jq '.compute.tags' | sed -e 's/"//g' | python3 /allspark/write_env.py
        source /allspark/env.sh
}

function mount_shared_volume {
        if [ ! -z $MASTER_IP ]; then
                mount $MASTER_IP:/shared /shared
        fi
}

function run_allspark_image {
        DNS=`cat /etc/resolv.conf | grep nameserver | awk '{print $2}' | sed 1q`
        docker run --dns $DNS -d --log-driver syslog --ulimit nofile=122880:122880 --env-file /allspark/env.sh --network host --mount type=bind,source=/shared,target=/shared allspark-worker:latest
        tail -f /dev/null
}

function set_credentials {
    RAMDISK_PATH=/ramdisk
    CREDENTIAL_PATH=$RAMDISK_PATH/.aws

    mkdir $RAMDISK_PATH
    mount -t tmpfs -o rw,size=1M tmpfs $RAMDISK_PATH
    mkdir $CREDENTIAL_PATH
    wget -O $CREDENTIAL_PATH/credentials $LOGGING_CREDENTIALS_URL
    ln -s $CREDENTIAL_PATH /root/.aws
}

function configure_logging {
    sed -i "s/_AZURE_SPARK_NODE_/$HOSTNAME/" /allspark/awslogs.conf
    curl https://s3.amazonaws.com/aws-cloudwatch/downloads/latest/awslogs-agent-setup.py -O
    python ./awslogs-agent-setup.py --region us-east-1 --non-interactive --configfile=/allspark/awslogs.conf
}

set_host_name
set_env_variables
set_credentials
configure_logging
mount_shared_volume
run_allspark_image
