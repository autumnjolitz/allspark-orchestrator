#!/bin/bash -x

while true; do
        /usr/bin/curl -s http://169.254.169.254/latest/meta-data/hostname -o /etc/hostname
        if [ "$?" == "0" ]; then
                break
        fi
        sleep 1
done
/usr/bin/hostname -F /etc/hostname
export HOSTNAME=`/usr/bin/hostname`

while true; do
        /usr/bin/curl -s http://169.254.169.254/latest/user-data -o /allspark/env.sh
        if [ "$?" == "0" ]; then
                break
        fi
        sleep 1
done

source /allspark/env.sh

export SPARK_WORKER_PORT=7078
export JAVA_HOME="/allspark/zulu8.40.0.25-ca-jdk8.0.222-linux_x64"
export SPARK_HOME="/allspark/spark-2.4.4-bin-hadoop2.7"
export PATH=$PATH:/allspark/zulu8.40.0.25-ca-jre8.0.222-linux_x64/bin/

function wait_for_spark_master {
    while true; do
        MASTER_ALIVE=`nc -z $MASTER_IP 7077`
        if [ "$?" == "0" ]; then
            break
        fi
        sleep 1
    done
}

function wait_for_spark_cluster {
    while true; do
        ALIVE_WORKERS=`curl -s http://localhost:8080/json/ | jq .aliveworkers`
        if [ "$ALIVE_WORKERS" == "$EXPECTED_WORKERS" ]; then
            break
        fi
        sleep 1
    done
}


if [ -z $MASTER_IP ]; then
    export MASTER_URL=spark://$(hostname -I | xargs):7077
    export EXECUTOR_MEMORY=`cat /proc/meminfo | grep MemTotal | awk '{ print int($2/1024/1024 - 1) }'`G
    export NUM_EXECUTORS=$EXPECTED_WORKERS

    $SPARK_HOME/sbin/start-master.sh
    wait_for_spark_cluster
    /allspark/run_monitor.py &
    /allspark/run
else
    wait_for_spark_master
    mount $MASTER_IP:/shared /shared
    $SPARK_HOME/sbin/start-slave.sh -d /shared spark://$MASTER_IP:7077
fi

tail -f /dev/null
